#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•Apple Healthæ•°æ®åˆ†æå™¨çš„å®Œæ•´å·¥ä½œæµç¨‹
"""

import os
import sys
import time
from datetime import datetime
from pathlib import Path

import psutil

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.analyzers.highlights import HighlightsGenerator
from src.analyzers.statistical import StatisticalAnalyzer
from src.core.xml_parser import parse_export_file
from src.processors.cleaner import DataCleaner
from src.processors.exporter import DataExporter
from src.visualization.reports import ReportGenerator


def get_memory_usage():
  """è·å–å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
  process = psutil.Process(os.getpid())
  return process.memory_info().rss / 1024 / 1024  # MB


def test_full_workflow():
  """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
  print("=== ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• ===")
  print(f"åˆå§‹å†…å­˜ä½¿ç”¨: {get_memory_usage():.2f} MB")

  start_time = time.time()
  start_mem = get_memory_usage()

  try:
    # 1. æ•°æ®è§£æ
    print("\n1. è§£æXMLæ•°æ®...")
    xml_path = Path("../export_data/export.xml")
    records, stats = parse_export_file(xml_path)
    print(f"âœ… è§£æå®Œæˆ: {len(records)} æ¡è®°å½•")

    # 2. æ•°æ®æ¸…æ´—
    print("\n2. æ•°æ®æ¸…æ´—...")
    cleaner = DataCleaner()
    cleaned_records, dedup_result = cleaner.deduplicate_by_time_window(records)
    print(
      f"âœ… æ¸…æ´—å®Œæˆ: {len(cleaned_records)} æ¡è®°å½• (ç§»é™¤ {dedup_result.removed_duplicates} æ¡é‡å¤)"
    )

    # 3. æ•°æ®è´¨é‡éªŒè¯
    print("\n3. æ•°æ®è´¨é‡éªŒè¯...")
    quality_report = cleaner.validate_data_quality(cleaned_records)
    print(f"âœ… è´¨é‡éªŒè¯å®Œæˆ: è´¨é‡è¯„åˆ† {quality_report.quality_score:.2f}")

    # 4. ç»Ÿè®¡åˆ†æ
    print("\n4. ç»Ÿè®¡åˆ†æ...")
    analyzer = StatisticalAnalyzer()
    stats_report = analyzer.generate_report(cleaned_records)
    print("âœ… ç»Ÿè®¡åˆ†æå®Œæˆ")

    # 5. äº®ç‚¹ç”Ÿæˆ
    print("\n5. äº®ç‚¹ç”Ÿæˆ...")
    highlights_gen = HighlightsGenerator()
    highlights = highlights_gen.generate_comprehensive_highlights()
    print(f"âœ… äº®ç‚¹ç”Ÿæˆå®Œæˆ: {len(highlights.insights)} ä¸ªæ´å¯Ÿ")

    # 6. æ•°æ®å¯¼å‡º
    print("\n6. æ•°æ®å¯¼å‡º...")
    exporter = DataExporter(Path("output"))
    export_stats = exporter.export_by_category(xml_path)
    print(
      f"âœ… æ•°æ®å¯¼å‡ºå®Œæˆ: {sum(len(files) for files in export_stats.values())} ä¸ªæ–‡ä»¶"
    )

    # 7. æŠ¥å‘Šç”Ÿæˆ
    print("\n7. æŠ¥å‘Šç”Ÿæˆ...")
    report_gen = ReportGenerator()

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æŠ¥å‘Šå¯¹è±¡
    class SimpleReport:
      def __init__(self, records, stats_report, quality_report, highlights):
        self.records = records
        self.stats_report = stats_report
        self.quality_report = quality_report
        self.highlights = highlights
        # æ·»åŠ ä¸€äº›å¿…éœ€çš„å±æ€§
        self.overall_wellness_score = 0.75
        self.data_range = (datetime.now(), datetime.now())
        self.data_completeness_score = 0.85
        self.analysis_confidence = 0.8

    simple_report = SimpleReport(
      cleaned_records, stats_report, quality_report, highlights
    )
    html_report = report_gen.generate_comprehensive_report(simple_report)
    print("âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

    # è®¡ç®—æ€»æ—¶é—´å’Œå†…å­˜
    total_time = time.time() - start_time
    total_mem = get_memory_usage() - start_mem

    print("\n=== é›†æˆæµ‹è¯•ç»“æœ ===")
    print(f"æ€»å¤„ç†æ—¶é—´: {total_time:.2f} ç§’")
    print(f"å†…å­˜ä½¿ç”¨: {total_mem:.2f} MB")
    print(f"å¤„ç†é€Ÿåº¦: {len(records) / total_time:.0f} æ¡/ç§’")
    print("âœ… ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é€šè¿‡")
    return True

  except Exception as e:
    print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
    import traceback

    traceback.print_exc()
    return False


def test_error_handling():
  """æµ‹è¯•é”™è¯¯å¤„ç†"""
  print("\n=== é”™è¯¯å¤„ç†æµ‹è¯• ===")

  # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
  try:
    parse_export_file(Path("nonexistent.xml"))
    print("âŒ åº”è¯¥æŠ›å‡ºæ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯")
    return False
  except FileNotFoundError:
    print("âœ… æ­£ç¡®å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯")

  # æµ‹è¯•ç©ºè®°å½•åˆ—è¡¨
  try:
    cleaner = DataCleaner()
    result = cleaner.deduplicate_by_time_window([])
    print("âœ… æ­£ç¡®å¤„ç†ç©ºè®°å½•åˆ—è¡¨")
  except Exception as e:
    print(f"âŒ å¤„ç†ç©ºè®°å½•åˆ—è¡¨å¤±è´¥: {e}")
    return False

  # æµ‹è¯•æ— æ•ˆæ•°æ®
  try:
    analyzer = StatisticalAnalyzer()
    result = analyzer.generate_report([])
    print("âœ… æ­£ç¡®å¤„ç†ç©ºç»Ÿè®¡åˆ†æ")
  except Exception as e:
    print(f"âŒ å¤„ç†ç©ºç»Ÿè®¡åˆ†æå¤±è´¥: {e}")
    return False

  print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
  return True


def test_edge_cases():
  """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
  print("\n=== è¾¹ç¼˜æƒ…å†µæµ‹è¯• ===")

  # æµ‹è¯•å•æ¡è®°å½•
  try:
    from src.core.data_models import QuantityRecord

    single_record = QuantityRecord(
      type="HKQuantityTypeIdentifierHeartRate",
      source_name="Test",
      start_date=datetime.now(),
      end_date=datetime.now(),
      value=70.0,
      unit="count/min",
      source_version="1.0",
      device="Test Device",
      creation_date=datetime.now(),
    )

    cleaner = DataCleaner()
    result, dedup_result = cleaner.deduplicate_by_time_window([single_record])
    assert len(result) == 1
    print("âœ… å•æ¡è®°å½•å¤„ç†æ­£ç¡®")
  except Exception as e:
    print(f"âŒ å•æ¡è®°å½•å¤„ç†å¤±è´¥: {e}")
    return False

  # æµ‹è¯•å¤§æ•°æ®é›†å­é›†
  try:
    xml_path = Path("../export_data/export.xml")
    records, stats = parse_export_file(xml_path)

    # åªå¤„ç†å‰1000æ¡è®°å½•
    subset = records[:1000]
    analyzer = StatisticalAnalyzer()
    report = analyzer.generate_report(subset)
    print("âœ… å¤§æ•°æ®é›†å­é›†å¤„ç†æ­£ç¡®")
  except Exception as e:
    print(f"âŒ å¤§æ•°æ®é›†å­é›†å¤„ç†å¤±è´¥: {e}")
    return False

  print("âœ… è¾¹ç¼˜æƒ…å†µæµ‹è¯•é€šè¿‡")
  return True


def main():
  """ä¸»å‡½æ•°"""
  print("å¼€å§‹ç³»ç»Ÿé›†æˆæµ‹è¯•...")

  # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
  Path("output").mkdir(exist_ok=True)
  Path("reports").mkdir(exist_ok=True)

  results = []

  # è¿è¡Œå„é¡¹æµ‹è¯•
  results.append(("å®Œæ•´å·¥ä½œæµç¨‹", test_full_workflow()))
  results.append(("é”™è¯¯å¤„ç†", test_error_handling()))
  results.append(("è¾¹ç¼˜æƒ…å†µ", test_edge_cases()))

  # è¾“å‡ºæ€»ç»“
  print("\n=== æµ‹è¯•æ€»ç»“ ===")
  passed = 0
  total = len(results)

  for test_name, success in results:
    status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
    print(f"{test_name}: {status}")
    if success:
      passed += 1

  print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")

  if passed == total:
    print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
    return 0
  else:
    print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
    return 1


if __name__ == "__main__":
  sys.exit(main())
